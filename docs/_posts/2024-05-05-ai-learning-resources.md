---
title: "From Padawan to Jedi Master to Whatever Yoda Was: A Curated List of AI Learning Resources"
excerpt: "Read on to discover a highly curated list of learning resources for artificial intelligence."
toc: true
toc_sticky: true
toc_label: "On This Page"
toc_icon: "robot"
last_modified_at: 2024-05-06T20:11:44
header:
  teaser: /assets/images/aieducation.jpg
categories:
  - blog
tags:
  - tech
---

<style>
  blockquote {
    font-style: normal !important;
  }
</style>

<script src="/assets/js/dynamic-link-targeting.js"></script>

![HelloThereGif](/assets/images/obiwan.gif)

This page is an ongoing list of learning resources for AI, ranging from stuff to get you started to stuff for diving deep. My goal is for this to be a targeted collection, quality over quantity. I started it for myselfâ€”a software engineer looking for ways to use AI in my workflowsâ€”and figured others might find it useful. **None of these are affiliate links.**

While being undeniably [so hot right now](https://knowyourmeme.com/memes/x-is-so-hot-right-now), AI education [isn't exactly a novel field](https://ai100.stanford.edu/). However, the overwhelming demand for content in the space is certainly new. This list is my attempt at [separating the wheat from the <s>shaft</s> chaff ðŸ˜](https://www.merriam-webster.com/dictionary/separate%20the%20wheat%20from%20the%20chaff).

**Nerd Note:** If you read the title of this article and went "What do you mean whatever Yoda was? Yoda was no mere Jedi Master, he was a Grand Master!", you're a nerd, and I love you. Yes, Yoda was a Jedi Grand Master, but it could be said he reached a level of power, influence, and status that went far beyond a title he [shared](https://starwars.fandom.com/wiki/Grand_Master#:~:text=The%20title%20was%20shared%20by%20Jedi%20Masters%20Xo%20Lahru%2C%20Pra%2DTre%20Veter%2C%20and%20Yoda%20during%20the%20High%20Republic%20Era) with several counterparts. Yoda's [Jedi lineage is insane](https://www.reddit.com/r/StarWarsCantina/comments/16wj3w1/master_yodas_jedi_lineage_is_an_insane_thing/). He is a master of masters many generations over. The Star Wars equivalent of [Abraham](https://en.wikipedia.org/wiki/Abraham). I believe he should have his own category, Chief Grand Master or something, especially considering his ability to remain prudent despite his infamous [ketamine addiction](https://knowyourmeme.com/memes/yodas-ketamine-addiction).
{: .notice--warning}

## Wading In

Most people have heard of AI in some way (ChatGPT, Midjourney, Firefly, Copilot, [Skynet](https://en.wikipedia.org/wiki/Skynet_(Terminator)), etc.), but if you want to get started with understanding what's going on under the hood, here are some good resources.

### Intro Courses

These courses walk you through the basics of AI. By basics, I mean the basics of what's happening behind the scenes, rather than the basics of using AI, such as signing up for an account to use ChatGPT. It's possible to be a decent enough AI user without understanding the concepts covered in these courses. You don't need to understand automotive engineering to drive a car, but if you want to be a better driver, understanding how your vehicle fundamentally works is undoubtedly a plus.

> **DeepLearning.AI:** [Generative AI For Everyone](https://www.coursera.org/learn/generative-ai-for-everyone)
>
This course, taught by [Andrew Ng](https://en.wikipedia.org/wiki/Andrew_Ng) is an excellent introduction to AI for anyone regardless of background. Andrew is a big deal in the AI community, like [three legendary Sannin](https://naruto.fandom.com/wiki/Sannin) level big. As a co-founder of [Google Brain](https://en.wikipedia.org/wiki/Google_Brain), he played a role in building a division that went on to make many significant contributions to the field of AI. He also founded [DeepLearning.AI](https://www.deeplearning.ai/about/) and co-founded [Coursera](https://en.wikipedia.org/wiki/Coursera), the platform where you'll find his course.
>
> **Free or Paid:** Free to audit, paid to access graded materials and get a certificate of completion.
{: .notice--primary}

> **Microsoft:** [Fundamental AI Concepts](https://learn.microsoft.com/en-us/training/modules/get-started-ai-fundamentals/) &
> **Google:** [Generative AI Learning Path](https://www.cloudskillsboost.google/paths/118)
>
Both Microsoft and Google have entry-level "get started with AI" courses that are solid. Each company has robust online education platforms, namely [Microsoft Learn](https://learn.microsoft.com/en-us/) and [Grow With Google](https://grow.google/). They offer the kind of free knowledge and training that makes me question if anyone really needs <i>4 long years</i> of undergraduate school to break into tech these days, but that's a topic for a different day.
>
> **Free or Paid:** Free.
{: .notice--primary}

### Excel + AI

There seems to be no limit to what can be done in Microsoft Excel. It is in many ways the foundation upon which the entire business world rests. The stuff people have pulled off in Excel is insane; like [this guy who built a game engine in it](https://www.reddit.com/r/gamedev/comments/11osft6/i_made_a_complete_game_engine_in_excel_and_then_i/). There are companies out there whose continued existence rests on a handful of Excel spreadsheets masquerading as databases. Dread it, run from it, Excel [remains all the same](https://www.notboring.co/p/excel-never-dies).

> **Ishan Anand:** [Spreadsheets Are All You Need](https://spreadsheets-are-all-you-need.ai/)
>
MIT grad [Ishan Anand](https://www.linkedin.com/in/ishananand/) came up with an awesome method of teaching AI using spreadsheets. His site features a series of videos that show how AI works using Excel as a familiar interface. It's a great low-code introduction to AI that's perfect for technical and non-technical audiences alike.
>
> **Free or Paid:** Free.
{: .notice--primary}

## Swimming Swiftly

If you're ready to go past the basics and get into building, customizing, and practically using AI, here are some resources to help you out. They aren't quite as deep as dropping everything to become a full-time AI Engineer, but they're sufficient for a tech-savvy individual to gain the knowledge needed to be dangerous.

### Prompt Engineering

The newfound field of Prompt _Engineering_ (a rather generous use of the word [engineering](https://www.mobilize.net/blog/the-misnomer-of-prompt-engineering)) can be crudely defined as "writing good instructions to get good output from AI". It's well worth understanding if you want to be an AI power user.

> **OpenAI:** [Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)
>
OpenAIâ€”creators of ChatGPTâ€”has a great guide on prompt engineering. Reading and understanding the content on this page can do wonders for improving your interactions with AI tools.
>
> **Free or Paid:** Free.
{: .notice--primary}

> **DAIR.AI:** [Prompt Engineering Knowledge Repository](https://github.com/dair-ai/Prompt-Engineering-Guide)
>
Next, check out this extremely thorough collection of guides, papers, lectures, notebooks, and resources for prompt engineering created and maintained by [DAIR.AI](https://github.com/dair-ai). They're an organization focused on "democratizing artificial intelligence research, education, and technologies". Everything you'd ever need to become a prompt engineering guru can be found here.
>
> **Free or Paid:** Free.
{: .notice--primary}

### Large Language Models

A large language model (LLM) is a type of AI trained on massive amounts of text data. This training enables it to understand and generate content in response to instructions (prompts). An example is OpenAI's GPT ([Generative Pre-trained Transformer](https://en.wikipedia.org/wiki/Generative_pre-trained_transformer)), where _Generative_ highlights its ability to create new content, _Pre-trained_ indicates it has been trained on a wide array of text data, and _Transformer_ refers to the modelâ€™s architecture, designed to handle complex patterns in data efficiently. Understanding LLMs is key to moving beyond the basics and towards AI expertise.

> **Andrej Karpathy:** [Intro to Large Language Models](https://www.youtube.com/watch?v=zjkBMFhNj_g)
>
Andrej Karpathy is an AI heavyweight, just read through his [Wikipedia page](https://en.wikipedia.org/wiki/Andrej_Karpathy) and you'll understand why. He's one of OpenAI's co-founders andâ€”in addition to being a brilliant engineerâ€”is an excellent educator, dropping AI knowledge for free on his YouTube channel. This 1-hour video where he introduces large language models comes highly recommended by engineers around the web. I see it linked in "How do I learn AI" threads all the time. It's certainly worth a watch!
>
> **Free or Paid:** Free.
{: .notice--primary}

> **Jay Mody:** [GPT In Just 60 Lines of NumPy](https://jaykmody.com/blog/gpt-from-scratch/)
>
To truly understand the inner workings of LLM's, there's no substitute for implementing one yourself. [Jay Mody's](https://jaykmody.com/) _GPT in 60 Lines of [NumPy](https://numpy.org/)_ is a great resource that walks you through building a GPT model from scratch with just 60 lines of code. It's a great read for anyone looking to understand the technical details behind LLMs and GPT.
>
> **Free or Paid:** Free.
{: .notice--primary}

### Python + AI

Python is [the programming language of AI](https://en.wikipedia.org/wiki/List_of_programming_languages_for_artificial_intelligence), so getting familiar with is worthwhile. These resources center on writing Python code to do stuff ([and thangs](https://www.urbandictionary.com/define.php?term=stuff%20and%20thangs)) with AI. If you're not familiar with Python, [Google's Python Class](https://developers.google.com/edu/python) is a good place to start.

> **OpenAI:** [API Developer Quickstart](https://platform.openai.com/docs/quickstart)
>
Quick and easy, this tutorial takes you through what you need to know to peel back the chatbot interface of LLMs and start building custom solutions. If you've only ever used ChatGPT, you'll be surprised at just how much more you can control model output using the API.
>
> **Free or Paid:** The quickstart can be completed for free (no charge for creating an API key), but to do anything beyond basic proof of concepts there is [a charge](https://openai.com/api/pricing).
{: .notice--primary}

> **DÃ©borah Mesquita:** [Python AI: How to Build a Neural Network & Make Predictions](https://realpython.com/python-ai-neural-network/)
>
[Real Python](https://realpython.com/) is a blog that puts out great learning resources, ranging from beginner to advanced, for coding with Python. [DÃ©borah Mesquita](https://deborahmesquita.com/) is a data scientist and member of the Real Python blogging team. She's written a great article that walks you through building a neural networkâ€”a foundational part of AIâ€”using Python. By the end of it, you'll know enough to be dangerous wielding Python as a tool for doing AI stuff ([and thangs](https://www.urbandictionary.com/define.php?term=stuff%20and%20thangs)).
>
> **Free or Paid:** Free.
{: .notice--primary}

> **Harvard University:** [Introduction to Artificial Intelligence with Python](https://www.edx.org/learn/artificial-intelligence/harvard-university-cs50-s-introduction-to-artificial-intelligence-with-python)
>
Harvard University's name speaks for itself. They put a surprising amount of their lectures and courses online for free, including their famous [freshman computer science](https://pll.harvard.edu/course/cs50-introduction-computer-science) class. This course introduces writing AI code using Python, which is crucial to interacting with the [APIs](https://en.wikipedia.org/wiki/API) of companies like [OpenAI](https://openai.com/index/openai-api) (backed by Microsoft), [Anthropic](https://www.anthropic.com/api) (backed by Amazon), [Meta](https://llama.meta.com/), and [Google](https://ai.google.dev/).
>
> **Free or Paid:** Free with optional paid upgrades.
{: .notice--primary}

## Diving Deep

If you're set on making AI your bread and butter, then this stuff is your jam ðŸ™ƒ. This is "I want to be an AI Researcher", "I want to be an AI Engineer", "I want to be a Machine Learning Engineer", and/or "I want to help advance humanity towards [artificial general intelligence](https://en.wikipedia.org/wiki/Artificial_general_intelligence)" territory.

It's beyond what's needed for practical application. The earlier resources are sufficient for being the "AI guy" at most companies. However, if you _really_ want to know your stuff when it comes to AIâ€”like going from the "car guy" to the "creator of novel automotive engineering advancements guy"â€”these resources will help.

### Foundational Texts

It might be all the rage right now, but AI isn't new. There have been several landmark works (many of them originating from researchers at Google, who deserve their flowers for advancing the field) that redefined what machines could do. To understand AIâ€”from first principlesâ€”you need to go back and read the papers, blogs, books, etc. that laid the foundation for our present AI-crazed world. Here are a few worth reading. Remember, these resources are for diving deep, way deep. These aren't light reads.

> **Alan Turing:** [Computing Machinery and Intelligence](https://academic.oup.com/mind/article/LIX/236/433/986238)
>
Ever heard of the [Turing Test](https://en.wikipedia.org/wiki/Turing_test)? The test for whether a machine has reached a level of intelligence indistinguishable from a human being. This paperâ€”written by legendary mathematician and computer scientist [Alan Turing](https://en.wikipedia.org/wiki/Alan_Turing)â€”is where it was first introduced. Published in 1950, it not only proposed the Turing Test but also delved into the possibilities and implications of what we now call artificial intelligence. Yes, this paper is old, but if you're trying to "know your stuff" when it comes to AI, reading its 28 or so pages is a must.
>
> **Free or Paid:** Free.
{: .notice--primary}

> **Google Brain:** [Attention Is All You Need](https://arxiv.org/pdf/1706.03762)
>
Published in [2017](https://en.wikipedia.org/wiki/Attention_Is_All_You_Need) by [Google Brain](https://en.wikipedia.org/wiki/Google_Brain), the paper _Attention Is All You Need_ introduced the [transformer model](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)), laying the foundation for modern generative AI. That is, the discoveries introduced in this paper are directly responsible for OpenAI's later breakthrough with ChatGPT. This paper contains the research, the knowledge, the discoveries, that made it all possible. Its revelations shifted AI from rigid, sequence-based processing to a flexible, efficient framework capable of understanding and generating human-like text. It's a seminal read for anyone looking to understand how we got to our current state of AI-generated content being both feasible and convincing.
>
> **Free or Paid:** Free.
{: .notice--primary}

> **Google Research:** [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
>
  In 2018, [Google Research](https://research.google/) revolutionized the way machines understand human language with the introduction of [BERT](https://en.wikipedia.org/wiki/BERT_(language_model)) (Bidirectional Encoder Representations from Transformers). This paper describes a method that allows AI to better comprehend the nuances and context of language as it's used in the real world. BERT set a new standard for natural language processing tasks, such as answering questions, translating languages, and even summarizing long articles. All of those learnings have become critical parts of major AI tools (ChatGPT, Claude, Gemini, etc.) If you're diving into AI, especially the language part, getting familiar with BERT is worth the time investment.
>
> **Free or Paid:** Free.
{: .notice--primary}

> **Stuart J. Russell & Peter Norvig:** [Artificial Intelligence: A Modern Approach](https://aima.cs.berkeley.edu/)
>
Do you remember when video games (excluding Madden and NBA 2K) ditched the "release a new game every year" format in favor of the "release a game and support it for years with DLCs and bug fixes" format? That's what this book is for AI. It is **the** AI textbook across universities globally and has been since its original publication in 1995. Despite its _ostensibly_ ancient publication date, it's nowhere near outdated. The authors periodically release new editions to keep with the times, each one improving on the last. The most recent edition was released in 2020 and is filled with the latest research, up-to-date examples, and insights into both the foundational theories and cutting-edge applications of AI. If you want to dive deep into AI, make this your swimming pool.
>
> **Free or Paid:** Technically speaking, [paid](https://www.amazon.com/Artificial-Intelligence-A-Modern-Approach-dp-0134610997/dp/0134610997/ref=dp_ob_title_bk), but actually, [free](https://dl.ebooksworld.ir/books/Artificial.Intelligence.A.Modern.Approach.4th.Edition.Peter.Norvig.%20Stuart.Russell.Pearson.9780134610993.EBooksWorld.ir.pdf).
{: .notice--primary}

### Advanced Concepts

Machine Learning, Neural Networks, and Deep Learning are all important domains of artificial intelligence. Understanding what they are, and the differences between them, is key to building AI expertise. Here's an **intentionally oversimplified** rundown of those terms.

* **Machine Learning** is all about teaching computers to get smarter over time, like giving them the building blocks and basic know-how to tackle problems on their own. But you can't just kick back and let the computer do all the workâ€”you'll still need to guide it along the way, tweaking things here and there to get the best results.
* **Neural Networks** are the engines that power many Machine Learning systems. They are designed to mimic the way the human brain operates, allowing them to learn from vast amounts of data. These networks consist of layers of interconnected parts that process data sequentially, enhancing their ability to make complex decisions and predictions.
* **Deep Learning** is like Machine Learning's overachieving sibling. It's a specific type of Machine Learning that relies heavily on Neural Networks to process massive amounts of data. Deep Learning excels at handling unstructured data like audio, video, and images. But much like Machine Learning, it still requires careful preparation and labeling of data before it can work its "magic".

This image from [Data Camp](https://www.datacamp.com/blog/how-to-learn-ai) does an excellent job of breaking down the terminology and their relationships.

![AITypesExplainer](/assets/images/ai-types-explainer.png)

What follows are specific learning resources for these advanced subdomains of AI.

#### Machine Learning

Notable learning resources for diving into Machine Learning.

> **Stanford University:** [Machine Learning Specialization](https://www.coursera.org/specializations/machine-learning-introduction)
>
This course bundle by Stanford Universityâ€”in partnership with DeepLearning.AI, a near-ubiquitous fixture in the AI education spaceâ€”offers a comprehensive dive into the world of Machine Learning. From basic concepts to advanced applications, it provides the kind of content that'll prove extremely valuable for those interested in building and manipulating AI models.
>
> **Free or Paid:** Free to audit, paid to access graded materials and get a certificate of completion.
{: .notice--primary}

> **Chirstopher Bishop:** [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)
>
[Christopher Bishop](https://en.wikipedia.org/wiki/Christopher_Bishop)â€”a [Microsoft Technical Fellow](https://en.wikipedia.org/wiki/Fellow#Industry_and_corporate_fellows) and director of their [AI Research Division](https://www.microsoft.com/en-us/research/lab/microsoft-research-ai4science/)â€”has been doing groundbreaking work in AI since before it was mainstream. His contributions have not only pushed the boundaries of what AI can achieve but also helped position Microsoft at the forefront of the field. His bookâ€”_Pattern Recognition and Machine Learning_â€”was first published in 2006 but has undergone continuous updates since. It's widely recognized as a foundational text for Machine Learning and is required reading in many programs around the world.
>
> **Free or Paid:** Free.
{: .notice--primary}

#### Neural Networks

Notable learning resources for diving into Neural Networks.

> **Andrej Karpathy:** [Neural Networks - Zero to Hero](https://karpathy.ai/zero-to-hero.html)
>
To thoroughly explore and understand Neural Networks, there are few better resources than this video series by [Andrej Karpathy](https://en.wikipedia.org/wiki/Andrej_Karpathy). He's one of OpenAI's co-founders, a former director of AI and Autopilot Vision at Tesla, and an all-around brilliant computer scientist. The YouTube playlist for the series can be found [here](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ), but Andrej also has a website for the course linked above.
>
> **Free or Paid:** Free.
{: .notice--primary}

> **Michael Nielsen:** [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)
>
[Michael Nielsen](https://en.wikipedia.org/wiki/Michael_Nielsen), a quantum physicist and AI researcher, authored the accessible yet profound _Neural Networks and Deep Learning_ in 2015. The book is a treasure trove for anyone diving into the mechanics of Neural Networks, which are a fundamental aspect of AI. The book exists online on his website, but if you prefer, you can likely find a PDF version with a [quick search](https://www.google.com/search?q=filetype%3Apdf+neural+networks+and+deep+learning+michael+nielsen).
>
> **Free or Paid:** Free.
{: .notice--primary}

#### Deep Learning

Notable learning resources for diving into Deep Learning.

> **Parand Tony Darugar:** [A Completely Non-Technical Explanation of AI and Deep Learning](https://www.parand.com/a-completely-non-technical-explanation-of-ai.html)
>
Compared to the other resources in this section, this is a lighter read. It's meant to get you familiar with the concepts behind AI and Deep Learning without the fancy terminology of academic writing. I find it refreshingly humorous while still being informative. It's a good starting place before wading into _deeper_ waters with _Deep_ Learning. [Parand Tony Dugar](https://www.linkedin.com/in/parand/) has an extensive history as a tech VP and entrepreneur. His blog features other similarly written articles that make AI concepts approachable in a non-stuffy way. It's worth [checking out](https://www.parand.com/)!
>
> **Free or Paid:** Free.
{: .notice--primary}

> **DeepLearning.AI:** [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)
>
This series of courses by [DeepLearning.AI](https://www.deeplearning.ai/) offers a structured approach to understanding the core concepts and techniques of Deep Learning. It gets into advanced concepts that aspiring AI Engineers will find valuable, all while maintaining a focus on real-world usage.
>
> **Free or Paid:** Free to audit, paid to access graded materials and get a certificate of completion.
{: .notice--primary}

> **Fast AI:** [Practical Deep Learning](https://course.fast.ai/)
>
If you already have coding experience and want to skip straight to practical applications of Deep Learning, this free course created by [fast.ai](https://www.fast.ai/about.html) is a good fit. It's less "reasoning from first principles" and more "here's what to know so that you can use this right now".
>
> **Free or Paid:** Free.
{: .notice--primary}

## Conclusion

There's a lot of content out there related to AI. With this post, I'm trying to pare things down to what's uniquely worth spending time on. Time is precious, and now more than ever, curated content that gets to the heart of what you're looking for is needed to make the most of it. There are resources on this page that I haven't even finished combing through. I relied heavily on suggestions from prominent AI experts and tech-savvy users on [Hacker News](https://news.ycombinator.com/), [Reddit](https://www.reddit.com/r/artificial/), and [Stack Exchange](https://stackexchange.com/sites) while compiling this list. I'm keeping it updated as I find new resources, or conclude that existing resources aren't worth keeping listed. Feel free to share your thoughts with me using my [contact page](/contact) or the comment section at the bottom. I hope you got some value out of this article!
